{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import sys\n",
    "sys.path.insert(0, 'lib')\n",
    "import numpy as np\n",
    "import random\n",
    "import pydicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "import pydicom\n",
    "from shutil import copyfile\n",
    "import nibabel as nib\n",
    "import scipy.ndimage as ndimage\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "from utils import make_giant_mat, make_dictionary, make_echo_dict\n",
    "from difference_map_utils import make_difference\n",
    "from cluster_utils import threshold_diffmaps, strip_empty_lines, resize\n",
    "from lesion_utils import *\n",
    "from inference_utils import run_inference\n",
    "from make_inference_csv import *\n",
    "from compare_segmentations import get_dice_scores, get_jaccard_indices, compare_segmentation_masks, compare_region_means, compare_region_changes\n",
    "from loss_functions import coefficient_of_variation\n",
    "from figure_utils import plot_mean_val_comparisons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from calculate_t2 import fit_t2\n",
    "from segmentation_refinement import *\n",
    "from projection import *\n",
    "from inference_utils import *\n",
    "import time\n",
    "import shutil\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slices(scan_dir):\n",
    "    '''\n",
    "    scan_dir = path to folder containing dicoms such that each dicom represents one slice of the image volume\n",
    "    '''\n",
    "    list_of_slices = glob.glob(\"{}/**\".format(scan_dir),\n",
    "                               recursive=True)\n",
    "    return list(filter(is_dicom, list_of_slices))\n",
    "\n",
    "def is_dicom(fullpath):\n",
    "    if os.path.isdir(fullpath):\n",
    "        return False\n",
    "    _, path = os.path.split(fullpath)\n",
    "    \n",
    "    path = path.lower()\n",
    "    if path[-4:] == \".dcm\":\n",
    "        return True\n",
    "    if not \".\" in path:\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/home/ubuntu/sample_longitudinal_data' #'./input'#\n",
    "vol_zip_list = np.sort([os.path.join(input_dir,i) for i in os.listdir(input_dir) if i[-4:]=='.zip'])\n",
    "\n",
    "# Get model\n",
    "model_weight_file = './model_weights/model_weights_quartileNormalization_echoAug.h5'\n",
    "model = get_model(model_weight_file)\n",
    "\n",
    "# Prepare CSV to write all results to\n",
    "region_list = ['all', 'superficial', 'deep','L', 'M', 'LA', 'LC', 'LP', 'MA', 'MC', 'MP', 'SL', 'DL', 'SM', 'DM','SLA', 'SLC', 'SLP', 'SMA', 'SMC', 'SMP', 'DLA', 'DLC', 'DLP', 'DMA', 'DMC', 'DMP']\n",
    "output_file = open(os.path.join(input_dir,'predictions.csv'), 'w')\n",
    "output_file.write('filename,'+','.join(region_list)+'\\n')\n",
    "\n",
    "total_time = 0\n",
    "for zip_num, vol_zip in enumerate(vol_zip_list):\n",
    "    print(\"Processing file %s...\" % os.path.basename(vol_zip))\n",
    "    time1 = time.time()\n",
    "    new_dir_name = os.path.join('./output', os.path.splitext(os.path.basename(vol_zip))[0])\n",
    "    os.makedirs(new_dir_name, exist_ok=True)\n",
    "    dicom_sub_dir = os.path.join(new_dir_name,\"dicom\")\n",
    "    raw_extract_dir = os.path.join(new_dir_name,\"raw_extract\")\n",
    "    os.makedirs(dicom_sub_dir, exist_ok=True)\n",
    "    \n",
    "    # Unzip the image volume. If the zip file contains an inner directory, move the files out of it. \n",
    "    with zipfile.ZipFile(vol_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(raw_extract_dir)\n",
    "    \n",
    "    slice_path_list = get_slices(raw_extract_dir)\n",
    "    for s in slice_path_list:\n",
    "        shutil.copy(s,os.path.join(dicom_sub_dir, os.path.basename(s)))\n",
    "    shutil.rmtree(raw_extract_dir)\n",
    "    \n",
    "\n",
    "    mese, times = assemble_4d_mese_v2(dicom_sub_dir)\n",
    "    \n",
    "    # If the slices are not 384x384, resize them\n",
    "    mese_resized = np.zeros((mese.shape[0], mese.shape[1], 384,384))\n",
    "    for s in range(mese.shape[0]):\n",
    "        for echo in range(mese.shape[1]):\n",
    "            mese_resized[s,echo,:,:] = resize(mese[s,echo,:,:], (384, 384),anti_aliasing=True)\n",
    "    mese = mese_resized\n",
    "    \n",
    "    \n",
    "    # Whiten the echo of each slice that is closest to 10ms \n",
    "    mese_white = []\n",
    "    for i,s in enumerate(mese):\n",
    "        if times[i][0] is not None:\n",
    "            slice_times = times[i]\n",
    "        else:\n",
    "            times[i][0]=times[i][1]-(times[i][2]-times[i][1])\n",
    "            slice_times = times[i]\n",
    "        slice_20ms_idx = np.argmin(slice_times-.02)\n",
    "        mese_white.append(whiten_img(s[slice_20ms_idx,:,:], normalization = 'quartile'))\n",
    "    mese_white = np.stack(mese_white).squeeze()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Estimate segmentation\n",
    "    seg_pred = model.predict(mese_white.reshape(-1,384,384,1), batch_size = 6)\n",
    "    seg_pred = seg_pred.squeeze()\n",
    "    \n",
    "    # Calculate T2 Map\n",
    "    t2 = fit_t2(mese, times, segmentation = seg_pred, n_jobs = 4, show_bad_pixels = False)\n",
    "    \n",
    "    # Refine the comparison segmentation by throwing out non-physiologic T2 values\n",
    "    print(\"A:\", np.sum(seg_pred))\n",
    "    seg_pred, t2 = t2_threshold(seg_pred, t2, t2_low=0, t2_high=100)\n",
    "    print(\"B:\", np.sum(seg_pred))\n",
    "    seg_pred, t2 = optimal_binarize(seg_pred, t2, prob_threshold=0.501, voxel_count_threshold=425)\n",
    "    print(\"C:\", np.sum(seg_pred))\n",
    "    \n",
    "    angular_bin = 5\n",
    "    visualization, thickness_map, min_rho_map, max_rho_map, avg_vals_dict, R = projection(t2, \n",
    "                                                                                       thickness_div = 0.5, \n",
    "                                                                                       values_threshold = 100,\n",
    "                                                                                       angular_bin = angular_bin, \n",
    "                                                                                       region_stat = 'mean',\n",
    "                                                                                       fig = False)\n",
    "\n",
    "    row_distance, column_distance = get_physical_dimensions(img_dir = dicom_sub_dir, \n",
    "                                                            t2_projection = visualization, \n",
    "                                                            projection_pixel_radius = R, \n",
    "                                                            angular_bin = angular_bin)\n",
    "    \n",
    "    t2_projection_dict = {}\n",
    "    t2_projection_dict['t2_projection'] = visualization\n",
    "    t2_projection_dict['thickness_map'] = thickness_map\n",
    "    t2_projection_dict['row_distance'] = row_distance\n",
    "    t2_projection_dict['column_distance'] = column_distance\n",
    "\n",
    "    # Save the t2 image, segmentation, and projection results\n",
    "    \n",
    "    ## Save the 3D binary segmentation mask as a numpy array\n",
    "    refined_seg_path = os.path.join(new_dir_name,\"segmentation_mask.npy\")\n",
    "    np.save(refined_seg_path, seg_pred)\n",
    "    \n",
    "    ## Save the 3D binary segmentation mask as a folder of CSV files\n",
    "    seg_sub_dir = os.path.join(new_dir_name,\"segmentation_mask_csv\")\n",
    "    os.makedirs(seg_sub_dir, exist_ok=True)\n",
    "    \n",
    "    for i,s in enumerate(seg_pred):\n",
    "        slice_path = os.path.join(seg_sub_dir,str(i).zfill(3)+\".csv\")\n",
    "        np.savetxt(slice_path, s,delimiter=\",\", fmt='%10.5f')\n",
    "                \n",
    "    ## Save the 3D T2 image as a numpy array\n",
    "    t2_img_path = os.path.join(new_dir_name,\"t2.npy\")\n",
    "    np.save(t2_img_path, t2)\n",
    "    \n",
    "    ## Save the 3D T2 image as a folder of CSV files\n",
    "    t2_sub_dir = os.path.join(new_dir_name,\"t2_csv\")\n",
    "    os.makedirs(t2_sub_dir, exist_ok=True)\n",
    "    \n",
    "    for i,s in enumerate(t2):\n",
    "        slice_path = os.path.join(t2_sub_dir,str(i).zfill(3)+\".csv\")\n",
    "        np.savetxt(slice_path, s,delimiter=\",\", fmt='%10.5f')\n",
    "    \n",
    "    ## Save the 2D projection of the T2 map as a numpy array\n",
    "    t2_projection_path = os.path.join(new_dir_name,\"t2_projection.npy\")\n",
    "    np.save(t2_projection_path, visualization)\n",
    "    \n",
    "    ## Save the 2D projection of the T2 map as a csv\n",
    "    t2_projection_csv_path = os.path.join(new_dir_name,\"t2_projection.csv\")\n",
    "    np.savetxt(t2_projection_csv_path, visualization,delimiter=\",\", fmt='%10.5f')\n",
    "    \n",
    "    ## Save the 2D projection thickness map as a numpy array\n",
    "    thickness_projection_path = os.path.join(new_dir_name,\"thickness_projection.npy\")\n",
    "    np.save(thickness_projection_path, thickness_map)\n",
    "    \n",
    "    ## Save the 2D projection thickness map as a csv\n",
    "    thickness_projection_csv_path = os.path.join(new_dir_name,\"thickness_projection.csv\")\n",
    "    np.savetxt(thickness_projection_csv_path, thickness_map,delimiter=\",\", fmt='%10.5f')\n",
    "    \n",
    "    ## Save the physical dimensions of the 2D projections as a json\n",
    "    projection_dimensions_dict = {}\n",
    "    projection_dimensions_dict['row_distance(mm)'] = row_distance\n",
    "    projection_dimensions_dict['column_distance(mm)'] = column_distance\n",
    "    projection_dimensions_dict_path = os.path.join(new_dir_name,\"projection_dimensions.json\")\n",
    "    with open(projection_dimensions_dict_path, 'w') as fp:\n",
    "        json.dump(projection_dimensions_dict, fp)\n",
    "        \n",
    "    ## Save the region average T2 dictionary as a json\n",
    "    t2_region_json_path = os.path.join(new_dir_name,\"region_mean_t2.json\")\n",
    "    with open(t2_region_json_path, 'w') as fp:\n",
    "        json.dump(avg_vals_dict, fp)\n",
    "    \n",
    "    time2 = time.time()\n",
    "    total_time = total_time + (time2-time1)\n",
    "    avg_pace = total_time / (zip_num+1)\n",
    "    files_remaining = len(vol_zip_list) - zip_num\n",
    "    print(\"Estimated time remaining (min):\",np.round(files_remaining*avg_pace/60,decimals=1))    \n",
    "    \n",
    "    output_file.write('%s,' % os.path.basename(vol_zip))\n",
    "    for r in region_list:\n",
    "        if r == 'DMP':\n",
    "            output_file.write('%d' % avg_vals_dict[r])\n",
    "        else:\n",
    "            output_file.write('%d,' % avg_vals_dict[r])\n",
    "\n",
    "    output_file.write('\\n')    \n",
    "\n",
    "output_file.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.load('/home/ubuntu/AutomaticKneeMRISegmentation/output/Hobart/t2_projection.npy')\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_list = ['all', 'superficial', 'deep','L', 'M', 'LA', 'LC', 'LP', 'MA', 'MC', 'MP', 'SL', 'DL', 'SM', 'DM','SLA', 'SLC', 'SLP', 'SMA', 'SMC', 'SMP', 'DLA', 'DLC', 'DLP', 'DMA', 'DMC', 'DMP']\n",
    "\n",
    "','.join(region_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(visualization)\n",
    "plt.show()\n",
    "print(visualization.shape)\n",
    "print(row_distance)\n",
    "print(column_distance)\n",
    "avg_vals_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Segmentations and T2 maps for your MESE images\n",
    "- If you provide a value for the 'expert_pd' argument, it will use your provided segmentations\n",
    "\n",
    "- If you provide a value for the 'to_segment_pd' argument, it will automatically segment the cartilage and then use that auto-segmentation to generate the T2 maps. By default, this uses our trained model, but model weights can be changed via the 'model_weights_file' argument and the model can be changed by altering the inference.get_model function in inference.py. \n",
    "\n",
    "- In addition to generating 3D T2 maps, it also provides the segmentations used to generate those T2 maps as 3D numpy arrays and json files that summarize the avg T2 value in each anatomical region of the cartilage plate\n",
    "\n",
    "- These results are all saved in the destinations specied in your Pandas dataframe (expert_pd or to_segment_pd) that you made in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_inference(to_segment_pd = predict_pd, model_weight_file = './model_weights/model_weights_quartileNormalization_echoAug.h5')\n",
    "# run_inference(expert_pd = predict_pd)\n",
    "\n",
    "# run_inference(expert_pd = expert1_pd)\n",
    "              \n",
    "# run_inference(expert_pd = expert2_pd)\n",
    "\n",
    "# We don't need to generate additional segmentations for the 'predict_subset_pd' or 'expert1_subset_pd' \n",
    "# because they are already generated as part of the 'predict_pd' and 'expert1_pd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip the expert segmentations if you haven't already\n",
    "# for file in os.listdir('/data/kevin_data/expert2/segmentations'):\n",
    "#     if file[-4:]=='.npy':\n",
    "#         temp = np.load(os.path.join('/data/kevin_data/expert2/segmentations',file))\n",
    "#         temp = np.flip(temp, axis = 0)\n",
    "#         np.save(os.path.join('/data/kevin_data/expert2/segmentations',file),temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use cluster analysis to identify cartilage lesions developing over time\n",
    "<img src=\"ClusterAnalysisExample.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "Find the percentage of the femoral cartilage surface area that is affected by cartilage lesions. In this context, a lesion is a localized area of cartilage that has increased in T2 value over time more than the surrounding area. You can adjust the settings in calculate_group_lesion_area() to make the criteria for lesions more or less strict based on how large a cluster must be and how much the T2 value must increase. \n",
    "\n",
    "Lesions are identified using methods adapted from the following manuscript:\n",
    "\n",
    "Monu, Uchechukwuka D., et al. \"Cluster analysis of quantitative MRI T2 and T1ρ relaxation times of cartilage identifies differences between healthy and ACL-injured individuals at 3T.\" Osteoarthritis and cartilage 25.4 (2017): 513-520.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paths = np.array(predict_pd.t2_projected_path)\n",
    "paths = [i + '.pickle' for i in paths]\n",
    "source1_time1 = np.sort([i for i in paths if i[-12]=='4'])\n",
    "source1_time2 = np.sort([i for i in paths if i[-12]=='8'])\n",
    "\n",
    "paths = np.array(expert1_pd.t2_projected_path)\n",
    "paths = [i + '.pickle' for i in paths]\n",
    "source2_time1 = np.sort([i for i in paths if i[-12]=='4'])\n",
    "source2_time2 = np.sort([i for i in paths if i[-12]=='8'])\n",
    "\n",
    "percentLesion_expert1 = calculate_group_lesion_area(timepoint1=source2_time1,\n",
    "                                                     timepoint2=source2_time2, \n",
    "#                                                      value_threshold = 9,\n",
    "                                                     sigma_multiple = 1,\n",
    "#                                                      area_value_threshold = 12.4,\n",
    "                                                     area_fraction_threshold = .01, \n",
    "                                                     area_percentile_threshold = None,\n",
    "                                                     display=False,\n",
    "                                                     save_path_list=None)\n",
    "\n",
    "print()\n",
    "print(\"--\"*10)\n",
    "\n",
    "\n",
    "percentLesion_predict = calculate_group_lesion_area(timepoint1=source1_time1,\n",
    "                                                     timepoint2=source1_time2, \n",
    "#                                                      value_threshold = 9,\n",
    "                                                     sigma_multiple = 1,\n",
    "#                                                      area_value_threshold = 12.4,\n",
    "                                                     area_fraction_threshold = .01, \n",
    "                                                     area_percentile_threshold = None,\n",
    "                                                     display=False,\n",
    "                                                     save_path_list = None)\n",
    "\n",
    "    \n",
    "\n",
    "# SAVE THE RESIZED PROJECTIONS AND LESION MAPS!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare two segmentation approaches (e.g. manual vs automated)\n",
    "- Quantify how closely the two segmentations agree with one another using Dice Score and Jaccard Index\n",
    "- Quantify how closely the downstream T2 measurements correlate for each region using Pearson correlation\n",
    "- Quantify the mean absolute difference in T2 measurements for each region\n",
    "- Quantify the agreement in the percentage of the cartilage plate that has lesion via Pearson correlation\n",
    "- Quantify the agreement in the lesions identified using Dice Score and Jaccard Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify how closely the two segmentations agree with one another using Dice Score and Jaccard Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Qmetric vs Model: Full test set\")\n",
    "dice_expert1_model, jaccard_expert1_model = compare_segmentation_masks(expert1_pd, \n",
    "                                                                       predict_pd, \n",
    "                                                                       display = True)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print()\n",
    "print(\"Qmetric vs Model: Test subset\")\n",
    "dice_expert1_model_subset, jaccard_expert1_model_subset = compare_segmentation_masks(expert1_subset_pd, \n",
    "                                                                                     predict_subset_pd, \n",
    "                                                                                     display = True)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print(\"Qmetric vs Expert 2: Test subset\")\n",
    "\n",
    "dice_expert1_expert2, jaccard_expert1_expert2 = compare_segmentation_masks(expert1_subset_pd, \n",
    "                                                                           expert2_pd, \n",
    "                                                                           display = True)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print(\"Model vs Expert 2: Test subset\")\n",
    "\n",
    "dice_expert1_expert2, jaccard_expert1_expert2 = compare_segmentation_masks(predict_subset_pd, \n",
    "                                                                           expert2_pd, \n",
    "                                                                           display = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how well they agree in terms of the average T2 value in each cartilage region of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlation_dict_e1_m, abs_diff_dict_e1_m, cv_e1_m, t_e1_m, cohen_e1_m = compare_region_means(list(expert1_pd.t2_region_json_path), \n",
    "                                                                            list(predict_pd.t2_region_json_path), \n",
    "                                                                            results_path=None,\n",
    "                                                                            correlation_method = 'spearman',\n",
    "                                                                            bland_altman = False)\n",
    "\n",
    "correlation_dict_e1_m_subset, abs_diff_dict_e1_m_subset, cv_e1_m_subset, t_e1_m_subset, cohen_e1_m_subset = compare_region_means(list(expert1_subset_pd.t2_region_json_path), \n",
    "                                                                                                list(predict_subset_pd.t2_region_json_path), \n",
    "                                                                                                results_path=None,\n",
    "                                                                                                correlation_method = 'spearman')\n",
    "\n",
    "correlation_dict_e1_e2, abs_diff_dict_e1_e2, cv_e1_e2, t_e1_e2, cohen_e1_e2 = compare_region_means(list(expert1_subset_pd.t2_region_json_path), \n",
    "                                                                            list(expert2_pd.t2_region_json_path), \n",
    "                                                                            results_path=None,\n",
    "                                                                            correlation_method = 'spearman')\n",
    "\n",
    "correlation_dict_e2_m, abs_diff_dict_e2_m, cv_e2_m, t_e2_m, _cohen_e1_e2 = compare_region_means(list(expert2_pd.t2_region_json_path), \n",
    "                                                                            list(predict_subset_pd.t2_region_json_path), \n",
    "                                                                            results_path=None,\n",
    "                                                                            correlation_method = 'spearman')\n",
    "\n",
    "plot_mean_val_comparisons(abs_diff_dict_e1_e2, \n",
    "                          abs_diff_dict_e1_m_subset, \n",
    "                          'Reader 2', \n",
    "                          'Model',\n",
    "                          error_bar='ci')\n",
    "\n",
    "# plot_mean_val_comparisons(abs_diff_dict_e1_e2, \n",
    "#                           abs_diff_dict_e1_m_subset, \n",
    "#                           'Reader 2', \n",
    "#                           'Model',\n",
    "#                           error_bar='ci')\n",
    "\n",
    "# plot_mean_val_comparisons(abs_diff_dict_e1_e2, \n",
    "#                           abs_diff_dict_e2_m, \n",
    "#                           'Reader 1', \n",
    "#                           'Model',\n",
    "#                           error_bar = 'ci')\n",
    "\n",
    "\n",
    "roi_list = np.array(['SLA', 'SLC', 'SLP', 'SMA', 'SMC', 'SMP', 'DLA', 'DLC', 'DLP', 'DMA', 'DMC', 'DMP'])\n",
    "print(\"CORRELATION: EXPERT1 vs Model (SUBSET)\")\n",
    "roi_corr_mean = 0\n",
    "for k,v in correlation_dict_e1_m_subset.items():\n",
    "    print(k, v)\n",
    "    if k in roi_list:\n",
    "        roi_corr_mean += v[0]\n",
    "roi_corr_mean = roi_corr_mean / len(roi_list)\n",
    "print()\n",
    "print(\"ROI CORR MEAN:\", roi_corr_mean)\n",
    "print()    \n",
    "print()\n",
    "\n",
    "print(\"Mean Abs Error: EXPERT1 vs Model (SUBSET\")\n",
    "roi_mae_mean = 0\n",
    "for k,v in abs_diff_dict_e1_m_subset.items():\n",
    "    print(k, v)\n",
    "    if k in roi_list:\n",
    "        roi_mae_mean += v[0]\n",
    "roi_mae_mean = roi_mae_mean / len(roi_list)\n",
    "print()\n",
    "print(\"ROI MAE MEAN:\", roi_mae_mean)\n",
    "print()    \n",
    "print()   \n",
    "print()\n",
    "print(\"Coefficient of Variation: EXPERT1 vs EXPERT2\")\n",
    "for k,v in cv_e1_e2.items():\n",
    "    print(k, v)\n",
    "    \n",
    "    \n",
    "    \n",
    "print()\n",
    "print(\"Cohen's D: EXPERT1 vs EXPERT2\")\n",
    "for k,v in cohen_e1_e2.items():\n",
    "    print(k, v)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how well they agree in terms of the average T2 change over time in each cartilage region of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expert1_regions = list(expert1_pd.t2_region_json_path)\n",
    "model_regions = list(predict_pd.t2_region_json_path)\n",
    "\n",
    "\n",
    "source1_regions1 = [i for i in expert1_regions if i[-6]=='4']# and '9120358' not in i]\n",
    "source1_regions2 = [i for i in expert1_regions if i[-6]=='8']#and '9120358' not in i]\n",
    "source2_regions1 = [i for i in model_regions if i[-6]=='4']#and '9120358' not in i]\n",
    "source2_regions2 = [i for i in model_regions if i[-6]=='8']#and '9120358' not in i]\n",
    "\n",
    "if len(source1_regions1)==len(source1_regions2):\n",
    "    catch = compare_region_changes(source1_regions1,\n",
    "                                   source1_regions2,\n",
    "                                   source2_regions1,\n",
    "                                   source2_regions2, \n",
    "                                   results_path=None,\n",
    "                                   correlation_method = 'spearman',\n",
    "                                   bland_altman = True)  \n",
    "    \n",
    "    (change_correlation_dict, change_mean_abs_diff_dict, change_cv_dict, change_ttest_dict, change_dict, change_cohen) = catch\n",
    "    \n",
    "print(\"CORRELATION EXPERT 1 VS MODEL\")\n",
    "for k,v in change_correlation_dict.items():\n",
    "    print(k, v)\n",
    "    \n",
    "\n",
    "print()\n",
    "print(\"MEAN ABS DIFFERENCE EXPERT 1 VS MODEL\")\n",
    "for k,v in change_mean_abs_diff_dict.items():\n",
    "    print(k, v)\n",
    "print()\n",
    "\n",
    "    \n",
    "print()\n",
    "print(\"MEAN CHANGE ACCORDING TO EXPERT 1\")\n",
    "for k,v in change_dict[1].items():\n",
    "    print(k, np.mean(v))\n",
    "    \n",
    "    \n",
    "print()\n",
    "print(\"COHEN's D ACCORDING TO EXPERT 1\")\n",
    "for k,v in change_cohen.items():\n",
    "    print(k, np.mean(v))\n",
    "\n",
    "\n",
    "for k in change_dict[1].keys():\n",
    "    plt.scatter(change_dict[1][k],change_dict[2][k]) \n",
    "    plt.title(k)\n",
    "    plt.plot([0,0],[-5,5],'orange')\n",
    "    plt.plot([-5,5],[0,0], 'orange')\n",
    "    plt.plot([-1.73,-1.73],[0,-4])\n",
    "    plt.plot([1.73, 1.73],[0,-4])\n",
    "    plt.plot([-.61,-.61],[0,-4])\n",
    "    plt.plot([.61, .61],[0,-4])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how well they agree in terms of the cartilage lesions that are identified as developing over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(percentLesion_expert1, percentLesion_predict)\n",
    "plt.title(\"Correlation:\" + str(spearmanr(percentLesion_expert1, percentLesion_predict)))\n",
    "plt.xlabel(\"Source 1: Fraction of cartilage affected\")\n",
    "plt.ylabel(\"Source 2: Fraction of cartilage affected\")\n",
    "plt.plot([.03,.15],[.03,.15])\n",
    "plt.plot(np.unique(percentLesion_expert1), np.poly1d(np.polyfit(percentLesion_expert1, percentLesion_predict, 1))(np.unique(percentLesion_expert1)))\n",
    "plt.legend(['unity','best fit','data points'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "bias_raw = np.mean(((np.array(percentLesion_expert1) - np.array(percentLesion_predict))))\n",
    "StD_raw = np.std(np.abs((np.array(percentLesion_expert1) - np.array(percentLesion_predict))))\n",
    "Mean_Abs_error = np.mean(np.abs((np.array(percentLesion_expert1) - np.array(percentLesion_predict))))\n",
    "StD_Abs_error = np.std(np.abs((np.array(percentLesion_expert1) - np.array(percentLesion_predict))))\n",
    "\n",
    "\n",
    "print()    \n",
    "print(\"Raw Error:\", bias_raw, \"+/-\", StD_raw)\n",
    "print(\"Mean absolute error:\", Mean_Abs_error)\n",
    "print(\"StD absolute error:\", StD_Abs_error)\n",
    "\n",
    "bias_relative = np.mean(((np.array(percentLesion_expert1) - np.array(percentLesion_predict))/np.array(percentLesion_expert1)))\n",
    "StD_relative = np.std(np.abs((np.array(percentLesion_expert1) - np.array(percentLesion_predict))/np.array(percentLesion_expert1)))\n",
    "    \n",
    "print()    \n",
    "print(\"Relative Error:\", bias_relative, \"+/-\", StD_relative)\n",
    " \n",
    "print(\"Mean Lesion Coverage for Expert 1:\", np.mean(percentLesion_expert1))\n",
    "print(\"Mean Lesion Coverage for Model:\", np.mean(percentLesion_predict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs((np.array(percentLesion_expert1) - np.array(percentLesion_predict))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('../data/kevin_data/qmetric/t2maps/9120358_4.npy')\n",
    "plt.imshow(a[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/kevin_data/qmetric/t2_projected/9909311_4.npy.pickle', 'rb') as handle:\n",
    "    dict_a = pickle.load(handle)\n",
    "\n",
    "with open('../data/kevin_data/qmetric/t2_projected/9909311_8.npy.pickle', 'rb') as handle:\n",
    "    dict_b = pickle.load(handle)\n",
    "    \n",
    "a = make_projection_proportional(dict_a)\n",
    "b = make_projection_proportional(dict_b)\n",
    "a,b = align_projections(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pix = np.sum(b!=0)\n",
    "where_b = np.where(b)\n",
    "where_a = np.where(a)\n",
    "\n",
    "dmap = np.zeros_like(b)\n",
    "for i in range(num_pix):\n",
    "    t2_b = b[where_b[0][i], where_b[1][i]]\n",
    "    \n",
    "    distances_r = where_a[0] - where_b[0][i]\n",
    "    distances_c = where_a[1] - where_b[1][i]\n",
    "    distances = np.sqrt(distances_r**2 + distances_c**2)\n",
    "    index = np.argmin(distances)\n",
    "    t2_a = a[where_a[0][index], where_a[1][index]]\n",
    "    \n",
    "    change = t2_b - t2_a\n",
    "    dmap[where_b[0][i], where_b[1][i]] = change\n",
    "plt.imshow(dmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difference_map_utils import eroded_and_mask\n",
    "mask = eroded_and_mask(dmap!=0,dmap!=0)\n",
    "dmap = dmap*mask\n",
    "plt.imshow(dmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.array([10,2,1,5])\n",
    "i = np.argsort(a)\n",
    "a[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([[10,1,5,3],[8,9,7,2],[1,2,3,4],[7,6,5,4]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[[0,0,1],[2,3,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
