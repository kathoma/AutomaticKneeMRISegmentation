{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import sys\n",
    "sys.path.insert(0, 'lib')\n",
    "import numpy as np\n",
    "import random\n",
    "import pydicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "import pydicom\n",
    "from shutil import copyfile\n",
    "import nibabel as nib\n",
    "import scipy.ndimage as ndimage\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "from utils import make_giant_mat, make_dictionary, make_echo_dict\n",
    "from difference_map_utils import make_difference\n",
    "from cluster_utils import threshold_diffmaps, strip_empty_lines, resize\n",
    "from lesion_utils import *\n",
    "from inference_utils import run_inference\n",
    "from make_inference_csv import *\n",
    "from compare_segmentations import get_dice_scores, get_jaccard_indices, compare_segmentation_masks, compare_region_means, compare_region_changes\n",
    "from loss_functions import coefficient_of_variation\n",
    "from figure_utils import plot_mean_val_comparisons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify which subjects you want to analyze using their OAI Patient ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9013634' '9120358' '9123289' '9245760' '9260036' '9279874' '9376146'\n",
      " '9405107' '9435250' '9458093' '9518827' '9529761' '9543086' '9909311']\n",
      "\n",
      "['9013634' '9120358' '9123289' '9245760' '9260036' '9279874' '9376146'\n",
      " '9405107' '9435250' '9458093' '9518827' '9529761' '9543086' '9909311']\n",
      "[4 8 8 4 8 4 8 8 4 8 8 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "with open('../data/dominik_data/train_val_test/pid_train.pickle', 'rb') as f:    \n",
    "    pid_train = pickle.load(f)\n",
    "    \n",
    "with open('../data/dominik_data/train_val_test/pid_val.pickle', 'rb') as f:    \n",
    "    pid_val = pickle.load(f)\n",
    "    \n",
    "with open('../data/dominik_data/train_val_test/pid_test.pickle', 'rb') as f:    \n",
    "    pid_test = pickle.load(f)\n",
    "\n",
    "# with open('../data/dominik_data/train_val_test/pid_test_expert2.pickle', 'rb') as f:\n",
    "#     pid_expert2 = pickle.load(f)\n",
    "    \n",
    "# with open('../data/dominik_data/train_val_test/pid_test_expert2_years.pickle', 'rb') as f:\n",
    "#     pid_expert2_yrs = pickle.load(f)\n",
    "\n",
    "with open('../data/dominik_data/train_val_test/pid_test_expert2_round2.pickle', 'rb') as f:\n",
    "    pid_expert2 = pickle.load(f)\n",
    "    \n",
    "with open('../data/dominik_data/train_val_test/pid_test_expert2_years_round2.pickle', 'rb') as f:\n",
    "    pid_expert2_yrs = pickle.load(f)\n",
    "\n",
    "print(np.sort(pid_test))\n",
    "print()\n",
    "print(np.sort(pid_expert2))\n",
    "print(pid_expert2_yrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Pandas Data Frame and CSV file to specify which image files you want to have analyzed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_dir</th>\n",
       "      <th>seg_path</th>\n",
       "      <th>refined_seg_path</th>\n",
       "      <th>t2_img_path</th>\n",
       "      <th>t2_projected_path</th>\n",
       "      <th>t2_region_json_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR4/9543086/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/954...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9543086_4.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9543...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9543...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR8/9543086/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/954...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9543086_8.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9543...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9543...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR4/9123289/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/912...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9123289_4.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9123...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR8/9123289/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/912...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9123289_8.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9123...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR4/9260036/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/926...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9260036_4.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9260...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9260...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR8/9260036/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/926...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9260036_8.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9260...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9260...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR4/9435250/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/943...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9435250_4.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9435...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9435...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR8/9435250/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/943...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9435250_8.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9435...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9435...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR4/9909311/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/990...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9909311_4.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9909...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9909...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR8/9909311/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/990...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9909311_8.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9909...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9909...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR4/9518827/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/951...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9518827_4.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9518...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9518...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR8/9518827/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/951...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9518827_8.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9518...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9518...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR4/9013634/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/901...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9013634_4.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9013...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR8/9013634/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/901...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9013634_8.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9013...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR4/9245760/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/924...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9245760_4.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9245...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9245...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR8/9245760/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/924...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9245760_8.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9245...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9245...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR4/9458093/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/945...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9458093_4.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9458...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9458...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR8/9458093/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/945...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9458093_8.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9458...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9458...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR4/9405107/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/940...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9405107_4.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9405...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9405...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR8/9405107/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/940...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9405107_8.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9405...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9405...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR4/9120358/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/912...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9120358_4.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9120...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9120...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR8/9120358/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/912...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9120358_8.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9120...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9120...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR4/9279874/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/927...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9279874_4.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9279...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9279...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR8/9279874/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/927...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9279874_8.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9279...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9279...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR4/9376146/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/937...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9376146_4.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9376...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9376...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR8/9376146/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/937...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9376146_8.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9376...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9376...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR4/9529761/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/952...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9529761_4.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9529...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9529...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/kevin_data/images/YR8/9529761/T2</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations/952...</td>\n",
       "      <td>../data/kevin_data/predicted/segmentations_ref...</td>\n",
       "      <td>../data/kevin_data/predicted/t2maps/9529761_8.npy</td>\n",
       "      <td>../data/kevin_data/predicted/t2_projected/9529...</td>\n",
       "      <td>../data/kevin_data/predicted/region_means/9529...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    img_dir  \\\n",
       "0  ../data/kevin_data/images/YR4/9543086/T2   \n",
       "0  ../data/kevin_data/images/YR8/9543086/T2   \n",
       "0  ../data/kevin_data/images/YR4/9123289/T2   \n",
       "0  ../data/kevin_data/images/YR8/9123289/T2   \n",
       "0  ../data/kevin_data/images/YR4/9260036/T2   \n",
       "0  ../data/kevin_data/images/YR8/9260036/T2   \n",
       "0  ../data/kevin_data/images/YR4/9435250/T2   \n",
       "0  ../data/kevin_data/images/YR8/9435250/T2   \n",
       "0  ../data/kevin_data/images/YR4/9909311/T2   \n",
       "0  ../data/kevin_data/images/YR8/9909311/T2   \n",
       "0  ../data/kevin_data/images/YR4/9518827/T2   \n",
       "0  ../data/kevin_data/images/YR8/9518827/T2   \n",
       "0  ../data/kevin_data/images/YR4/9013634/T2   \n",
       "0  ../data/kevin_data/images/YR8/9013634/T2   \n",
       "0  ../data/kevin_data/images/YR4/9245760/T2   \n",
       "0  ../data/kevin_data/images/YR8/9245760/T2   \n",
       "0  ../data/kevin_data/images/YR4/9458093/T2   \n",
       "0  ../data/kevin_data/images/YR8/9458093/T2   \n",
       "0  ../data/kevin_data/images/YR4/9405107/T2   \n",
       "0  ../data/kevin_data/images/YR8/9405107/T2   \n",
       "0  ../data/kevin_data/images/YR4/9120358/T2   \n",
       "0  ../data/kevin_data/images/YR8/9120358/T2   \n",
       "0  ../data/kevin_data/images/YR4/9279874/T2   \n",
       "0  ../data/kevin_data/images/YR8/9279874/T2   \n",
       "0  ../data/kevin_data/images/YR4/9376146/T2   \n",
       "0  ../data/kevin_data/images/YR8/9376146/T2   \n",
       "0  ../data/kevin_data/images/YR4/9529761/T2   \n",
       "0  ../data/kevin_data/images/YR8/9529761/T2   \n",
       "\n",
       "                                            seg_path  \\\n",
       "0  ../data/kevin_data/predicted/segmentations/954...   \n",
       "0  ../data/kevin_data/predicted/segmentations/954...   \n",
       "0  ../data/kevin_data/predicted/segmentations/912...   \n",
       "0  ../data/kevin_data/predicted/segmentations/912...   \n",
       "0  ../data/kevin_data/predicted/segmentations/926...   \n",
       "0  ../data/kevin_data/predicted/segmentations/926...   \n",
       "0  ../data/kevin_data/predicted/segmentations/943...   \n",
       "0  ../data/kevin_data/predicted/segmentations/943...   \n",
       "0  ../data/kevin_data/predicted/segmentations/990...   \n",
       "0  ../data/kevin_data/predicted/segmentations/990...   \n",
       "0  ../data/kevin_data/predicted/segmentations/951...   \n",
       "0  ../data/kevin_data/predicted/segmentations/951...   \n",
       "0  ../data/kevin_data/predicted/segmentations/901...   \n",
       "0  ../data/kevin_data/predicted/segmentations/901...   \n",
       "0  ../data/kevin_data/predicted/segmentations/924...   \n",
       "0  ../data/kevin_data/predicted/segmentations/924...   \n",
       "0  ../data/kevin_data/predicted/segmentations/945...   \n",
       "0  ../data/kevin_data/predicted/segmentations/945...   \n",
       "0  ../data/kevin_data/predicted/segmentations/940...   \n",
       "0  ../data/kevin_data/predicted/segmentations/940...   \n",
       "0  ../data/kevin_data/predicted/segmentations/912...   \n",
       "0  ../data/kevin_data/predicted/segmentations/912...   \n",
       "0  ../data/kevin_data/predicted/segmentations/927...   \n",
       "0  ../data/kevin_data/predicted/segmentations/927...   \n",
       "0  ../data/kevin_data/predicted/segmentations/937...   \n",
       "0  ../data/kevin_data/predicted/segmentations/937...   \n",
       "0  ../data/kevin_data/predicted/segmentations/952...   \n",
       "0  ../data/kevin_data/predicted/segmentations/952...   \n",
       "\n",
       "                                    refined_seg_path  \\\n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "0  ../data/kevin_data/predicted/segmentations_ref...   \n",
       "\n",
       "                                         t2_img_path  \\\n",
       "0  ../data/kevin_data/predicted/t2maps/9543086_4.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9543086_8.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9123289_4.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9123289_8.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9260036_4.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9260036_8.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9435250_4.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9435250_8.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9909311_4.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9909311_8.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9518827_4.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9518827_8.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9013634_4.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9013634_8.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9245760_4.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9245760_8.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9458093_4.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9458093_8.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9405107_4.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9405107_8.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9120358_4.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9120358_8.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9279874_4.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9279874_8.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9376146_4.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9376146_8.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9529761_4.npy   \n",
       "0  ../data/kevin_data/predicted/t2maps/9529761_8.npy   \n",
       "\n",
       "                                   t2_projected_path  \\\n",
       "0  ../data/kevin_data/predicted/t2_projected/9543...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9543...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9123...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9123...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9260...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9260...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9435...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9435...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9909...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9909...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9518...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9518...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9013...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9013...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9245...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9245...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9458...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9458...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9405...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9405...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9120...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9120...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9279...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9279...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9376...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9376...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9529...   \n",
       "0  ../data/kevin_data/predicted/t2_projected/9529...   \n",
       "\n",
       "                                 t2_region_json_path  \n",
       "0  ../data/kevin_data/predicted/region_means/9543...  \n",
       "0  ../data/kevin_data/predicted/region_means/9543...  \n",
       "0  ../data/kevin_data/predicted/region_means/9123...  \n",
       "0  ../data/kevin_data/predicted/region_means/9123...  \n",
       "0  ../data/kevin_data/predicted/region_means/9260...  \n",
       "0  ../data/kevin_data/predicted/region_means/9260...  \n",
       "0  ../data/kevin_data/predicted/region_means/9435...  \n",
       "0  ../data/kevin_data/predicted/region_means/9435...  \n",
       "0  ../data/kevin_data/predicted/region_means/9909...  \n",
       "0  ../data/kevin_data/predicted/region_means/9909...  \n",
       "0  ../data/kevin_data/predicted/region_means/9518...  \n",
       "0  ../data/kevin_data/predicted/region_means/9518...  \n",
       "0  ../data/kevin_data/predicted/region_means/9013...  \n",
       "0  ../data/kevin_data/predicted/region_means/9013...  \n",
       "0  ../data/kevin_data/predicted/region_means/9245...  \n",
       "0  ../data/kevin_data/predicted/region_means/9245...  \n",
       "0  ../data/kevin_data/predicted/region_means/9458...  \n",
       "0  ../data/kevin_data/predicted/region_means/9458...  \n",
       "0  ../data/kevin_data/predicted/region_means/9405...  \n",
       "0  ../data/kevin_data/predicted/region_means/9405...  \n",
       "0  ../data/kevin_data/predicted/region_means/9120...  \n",
       "0  ../data/kevin_data/predicted/region_means/9120...  \n",
       "0  ../data/kevin_data/predicted/region_means/9279...  \n",
       "0  ../data/kevin_data/predicted/region_means/9279...  \n",
       "0  ../data/kevin_data/predicted/region_means/9376...  \n",
       "0  ../data/kevin_data/predicted/region_means/9376...  \n",
       "0  ../data/kevin_data/predicted/region_means/9529...  \n",
       "0  ../data/kevin_data/predicted/region_means/9529...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_pd = make_expert_csv_all_years(pID=pid_test,img_dir='../data/kevin_data/images', dir_to_save='../data/kevin_data/predicted')\n",
    "\n",
    "expert1_pd = make_expert_csv_all_years(pID=pid_test, img_dir='../data/kevin_data/images',dir_to_save='../data/kevin_data/qmetric')\n",
    "\n",
    "# We only have segmentations for one timepoint for the subjects segmented by expert2 and these are nifti files\n",
    "expert2_pd = make_expert_csv_specific_years(pID=pid_expert2, \n",
    "                                            years=pid_expert2_yrs, \n",
    "                                            img_dir='../data/kevin_data/images', \n",
    "                                            dir_to_save='../data/kevin_data/expert2', \n",
    "                                            seg_provided=True, \n",
    "                                            seg_format = \"numpy\")\n",
    "\n",
    "predict_subset_pd = make_expert_csv_specific_years(pID=pid_expert2, \n",
    "                                            years=pid_expert2_yrs, \n",
    "                                            img_dir='../data/kevin_data/images', \n",
    "                                            dir_to_save='../data/kevin_data/predicted', \n",
    "                                            seg_provided=True, \n",
    "                                            seg_format = \"numpy\",\n",
    "                                            csv_filename = 'file_paths_subset.csv')\n",
    "\n",
    "expert1_subset_pd = make_expert_csv_specific_years(pID=pid_expert2, \n",
    "                                            years=pid_expert2_yrs, \n",
    "                                            img_dir='../data/kevin_data/images', \n",
    "                                            dir_to_save='../data/kevin_data/qmetric', \n",
    "                                            seg_provided=True, \n",
    "                                            seg_format = \"numpy\",\n",
    "                                            csv_filename = 'file_paths_subset.csv')\n",
    "predict_pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Segmentations and T2 maps for your MESE images\n",
    "- If you provide a value for the 'expert_pd' argument, it will use your provided segmentations\n",
    "\n",
    "- If you provide a value for the 'to_segment_pd' argument, it will automatically segment the cartilage and then use that auto-segmentation to generate the T2 maps. By default, this uses our trained model, but model weights can be changed via the 'model_weights_file' argument and the model can be changed by altering the inference.get_model function in inference.py. \n",
    "\n",
    "- In addition to generating 3D T2 maps, it also provides the segmentations used to generate those T2 maps as 3D numpy arrays and json files that summarize the avg T2 value in each anatomical region of the cartilage plate\n",
    "\n",
    "- These results are all saved in the destinations specied in your Pandas dataframe (expert_pd or to_segment_pd) that you made in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_inference(to_segment_pd = predict_pd, model_weight_file = './model_weights/model_weights_quartileNormalization_echoAug.h5')\n",
    "# run_inference(expert_pd = predict_pd)\n",
    "\n",
    "# run_inference(expert_pd = expert1_pd)\n",
    "              \n",
    "# run_inference(expert_pd = expert2_pd)\n",
    "\n",
    "# We don't need to generate additional segmentations for the 'predict_subset_pd' or 'expert1_subset_pd' \n",
    "# because they are already generated as part of the 'predict_pd' and 'expert1_pd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip the expert segmentations if you haven't already\n",
    "# for file in os.listdir('/data/kevin_data/expert2/segmentations'):\n",
    "#     if file[-4:]=='.npy':\n",
    "#         temp = np.load(os.path.join('/data/kevin_data/expert2/segmentations',file))\n",
    "#         temp = np.flip(temp, axis = 0)\n",
    "#         np.save(os.path.join('/data/kevin_data/expert2/segmentations',file),temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use cluster analysis to identify cartilage lesions developing over time\n",
    "<img src=\"ClusterAnalysisExample.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "Find the percentage of the femoral cartilage surface area that is affected by cartilage lesions. In this context, a lesion is a localized area of cartilage that has increased in T2 value over time more than the surrounding area. You can adjust the settings in calculate_group_lesion_area() to make the criteria for lesions more or less strict based on how large a cluster must be and how much the T2 value must increase. \n",
    "\n",
    "Lesions are identified using methods adapted from the following manuscript:\n",
    "\n",
    "Monu, Uchechukwuka D., et al. \"Cluster analysis of quantitative MRI T2 and T1œÅ relaxation times of cartilage identifies differences between healthy and ACL-injured individuals at 3T.\" Osteoarthritis and cartilage 25.4 (2017): 513-520.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paths = np.array(predict_pd.t2_projected_path)\n",
    "paths = [i + '.pickle' for i in paths]\n",
    "source1_time1 = np.sort([i for i in paths if i[-12]=='4'])\n",
    "source1_time2 = np.sort([i for i in paths if i[-12]=='8'])\n",
    "\n",
    "paths = np.array(expert1_pd.t2_projected_path)\n",
    "paths = [i + '.pickle' for i in paths]\n",
    "source2_time1 = np.sort([i for i in paths if i[-12]=='4'])\n",
    "source2_time2 = np.sort([i for i in paths if i[-12]=='8'])\n",
    "\n",
    "percentLesion_expert1 = calculate_group_lesion_area(timepoint1=source2_time1,\n",
    "                                                     timepoint2=source2_time2, \n",
    "#                                                      value_threshold = 9,\n",
    "                                                     sigma_multiple = 1,\n",
    "#                                                      area_value_threshold = 12.4,\n",
    "                                                     area_fraction_threshold = .01, \n",
    "                                                     area_percentile_threshold = None,\n",
    "                                                     display=False,\n",
    "                                                     save_path_list=None)\n",
    "\n",
    "print()\n",
    "print(\"--\"*10)\n",
    "\n",
    "\n",
    "percentLesion_predict = calculate_group_lesion_area(timepoint1=source1_time1,\n",
    "                                                     timepoint2=source1_time2, \n",
    "#                                                      value_threshold = 9,\n",
    "                                                     sigma_multiple = 1,\n",
    "#                                                      area_value_threshold = 12.4,\n",
    "                                                     area_fraction_threshold = .01, \n",
    "                                                     area_percentile_threshold = None,\n",
    "                                                     display=False,\n",
    "                                                     save_path_list = None)\n",
    "\n",
    "    \n",
    "\n",
    "# SAVE THE RESIZED PROJECTIONS AND LESION MAPS!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare two segmentation approaches (e.g. manual vs automated)\n",
    "- Quantify how closely the two segmentations agree with one another using Dice Score and Jaccard Index\n",
    "- Quantify how closely the downstream T2 measurements correlate for each region using Pearson correlation\n",
    "- Quantify the mean absolute difference in T2 measurements for each region\n",
    "- Quantify the agreement in the percentage of the cartilage plate that has lesion via Pearson correlation\n",
    "- Quantify the agreement in the lesions identified using Dice Score and Jaccard Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify how closely the two segmentations agree with one another using Dice Score and Jaccard Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Qmetric vs Model: Full test set\")\n",
    "dice_expert1_model, jaccard_expert1_model = compare_segmentation_masks(expert1_pd, \n",
    "                                                                       predict_pd, \n",
    "                                                                       display = True)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print()\n",
    "print(\"Qmetric vs Model: Test subset\")\n",
    "dice_expert1_model_subset, jaccard_expert1_model_subset = compare_segmentation_masks(expert1_subset_pd, \n",
    "                                                                                     predict_subset_pd, \n",
    "                                                                                     display = True)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print(\"Qmetric vs Expert 2: Test subset\")\n",
    "\n",
    "dice_expert1_expert2, jaccard_expert1_expert2 = compare_segmentation_masks(expert1_subset_pd, \n",
    "                                                                           expert2_pd, \n",
    "                                                                           display = True)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print(\"Model vs Expert 2: Test subset\")\n",
    "\n",
    "dice_expert1_expert2, jaccard_expert1_expert2 = compare_segmentation_masks(predict_subset_pd, \n",
    "                                                                           expert2_pd, \n",
    "                                                                           display = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how well they agree in terms of the average T2 value in each cartilage region of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlation_dict_e1_m, abs_diff_dict_e1_m, cv_e1_m, t_e1_m, cohen_e1_m = compare_region_means(list(expert1_pd.t2_region_json_path), \n",
    "                                                                            list(predict_pd.t2_region_json_path), \n",
    "                                                                            results_path=None,\n",
    "                                                                            correlation_method = 'spearman',\n",
    "                                                                            bland_altman = False)\n",
    "\n",
    "correlation_dict_e1_m_subset, abs_diff_dict_e1_m_subset, cv_e1_m_subset, t_e1_m_subset, cohen_e1_m_subset = compare_region_means(list(expert1_subset_pd.t2_region_json_path), \n",
    "                                                                                                list(predict_subset_pd.t2_region_json_path), \n",
    "                                                                                                results_path=None,\n",
    "                                                                                                correlation_method = 'spearman')\n",
    "\n",
    "correlation_dict_e1_e2, abs_diff_dict_e1_e2, cv_e1_e2, t_e1_e2, cohen_e1_e2 = compare_region_means(list(expert1_subset_pd.t2_region_json_path), \n",
    "                                                                            list(expert2_pd.t2_region_json_path), \n",
    "                                                                            results_path=None,\n",
    "                                                                            correlation_method = 'spearman')\n",
    "\n",
    "correlation_dict_e2_m, abs_diff_dict_e2_m, cv_e2_m, t_e2_m, _cohen_e1_e2 = compare_region_means(list(expert2_pd.t2_region_json_path), \n",
    "                                                                            list(predict_subset_pd.t2_region_json_path), \n",
    "                                                                            results_path=None,\n",
    "                                                                            correlation_method = 'spearman')\n",
    "\n",
    "plot_mean_val_comparisons(abs_diff_dict_e1_e2, \n",
    "                          abs_diff_dict_e1_m_subset, \n",
    "                          'Reader 2', \n",
    "                          'Model',\n",
    "                          error_bar='ci')\n",
    "\n",
    "# plot_mean_val_comparisons(abs_diff_dict_e1_e2, \n",
    "#                           abs_diff_dict_e1_m_subset, \n",
    "#                           'Reader 2', \n",
    "#                           'Model',\n",
    "#                           error_bar='ci')\n",
    "\n",
    "# plot_mean_val_comparisons(abs_diff_dict_e1_e2, \n",
    "#                           abs_diff_dict_e2_m, \n",
    "#                           'Reader 1', \n",
    "#                           'Model',\n",
    "#                           error_bar = 'ci')\n",
    "\n",
    "\n",
    "roi_list = np.array(['SLA', 'SLC', 'SLP', 'SMA', 'SMC', 'SMP', 'DLA', 'DLC', 'DLP', 'DMA', 'DMC', 'DMP'])\n",
    "print(\"CORRELATION: EXPERT1 vs Model (SUBSET)\")\n",
    "roi_corr_mean = 0\n",
    "for k,v in correlation_dict_e1_m_subset.items():\n",
    "    print(k, v)\n",
    "    if k in roi_list:\n",
    "        roi_corr_mean += v[0]\n",
    "roi_corr_mean = roi_corr_mean / len(roi_list)\n",
    "print()\n",
    "print(\"ROI CORR MEAN:\", roi_corr_mean)\n",
    "print()    \n",
    "print()\n",
    "\n",
    "print(\"Mean Abs Error: EXPERT1 vs Model (SUBSET\")\n",
    "roi_mae_mean = 0\n",
    "for k,v in abs_diff_dict_e1_m_subset.items():\n",
    "    print(k, v)\n",
    "    if k in roi_list:\n",
    "        roi_mae_mean += v[0]\n",
    "roi_mae_mean = roi_mae_mean / len(roi_list)\n",
    "print()\n",
    "print(\"ROI MAE MEAN:\", roi_mae_mean)\n",
    "print()    \n",
    "print()   \n",
    "print()\n",
    "print(\"Coefficient of Variation: EXPERT1 vs EXPERT2\")\n",
    "for k,v in cv_e1_e2.items():\n",
    "    print(k, v)\n",
    "    \n",
    "    \n",
    "    \n",
    "print()\n",
    "print(\"Cohen's D: EXPERT1 vs EXPERT2\")\n",
    "for k,v in cohen_e1_e2.items():\n",
    "    print(k, v)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how well they agree in terms of the average T2 change over time in each cartilage region of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expert1_regions = list(expert1_pd.t2_region_json_path)\n",
    "model_regions = list(predict_pd.t2_region_json_path)\n",
    "\n",
    "\n",
    "source1_regions1 = [i for i in expert1_regions if i[-6]=='4']# and '9120358' not in i]\n",
    "source1_regions2 = [i for i in expert1_regions if i[-6]=='8']#and '9120358' not in i]\n",
    "source2_regions1 = [i for i in model_regions if i[-6]=='4']#and '9120358' not in i]\n",
    "source2_regions2 = [i for i in model_regions if i[-6]=='8']#and '9120358' not in i]\n",
    "\n",
    "if len(source1_regions1)==len(source1_regions2):\n",
    "    catch = compare_region_changes(source1_regions1,\n",
    "                                   source1_regions2,\n",
    "                                   source2_regions1,\n",
    "                                   source2_regions2, \n",
    "                                   results_path=None,\n",
    "                                   correlation_method = 'spearman',\n",
    "                                   bland_altman = True)  \n",
    "    \n",
    "    (change_correlation_dict, change_mean_abs_diff_dict, change_cv_dict, change_ttest_dict, change_dict, change_cohen) = catch\n",
    "    \n",
    "print(\"CORRELATION EXPERT 1 VS MODEL\")\n",
    "for k,v in change_correlation_dict.items():\n",
    "    print(k, v)\n",
    "    \n",
    "\n",
    "print()\n",
    "print(\"MEAN ABS DIFFERENCE EXPERT 1 VS MODEL\")\n",
    "for k,v in change_mean_abs_diff_dict.items():\n",
    "    print(k, v)\n",
    "print()\n",
    "\n",
    "    \n",
    "print()\n",
    "print(\"MEAN CHANGE ACCORDING TO EXPERT 1\")\n",
    "for k,v in change_dict[1].items():\n",
    "    print(k, np.mean(v))\n",
    "    \n",
    "    \n",
    "print()\n",
    "print(\"COHEN's D ACCORDING TO EXPERT 1\")\n",
    "for k,v in change_cohen.items():\n",
    "    print(k, np.mean(v))\n",
    "\n",
    "\n",
    "for k in change_dict[1].keys():\n",
    "    plt.scatter(change_dict[1][k],change_dict[2][k]) \n",
    "    plt.title(k)\n",
    "    plt.plot([0,0],[-5,5],'orange')\n",
    "    plt.plot([-5,5],[0,0], 'orange')\n",
    "    plt.plot([-1.73,-1.73],[0,-4])\n",
    "    plt.plot([1.73, 1.73],[0,-4])\n",
    "    plt.plot([-.61,-.61],[0,-4])\n",
    "    plt.plot([.61, .61],[0,-4])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how well they agree in terms of the cartilage lesions that are identified as developing over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(percentLesion_expert1, percentLesion_predict)\n",
    "plt.title(\"Correlation:\" + str(spearmanr(percentLesion_expert1, percentLesion_predict)))\n",
    "plt.xlabel(\"Source 1: Fraction of cartilage affected\")\n",
    "plt.ylabel(\"Source 2: Fraction of cartilage affected\")\n",
    "plt.plot([.03,.15],[.03,.15])\n",
    "plt.plot(np.unique(percentLesion_expert1), np.poly1d(np.polyfit(percentLesion_expert1, percentLesion_predict, 1))(np.unique(percentLesion_expert1)))\n",
    "plt.legend(['unity','best fit','data points'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "bias_raw = np.mean(((np.array(percentLesion_expert1) - np.array(percentLesion_predict))))\n",
    "StD_raw = np.std(np.abs((np.array(percentLesion_expert1) - np.array(percentLesion_predict))))\n",
    "Mean_Abs_error = np.mean(np.abs((np.array(percentLesion_expert1) - np.array(percentLesion_predict))))\n",
    "StD_Abs_error = np.std(np.abs((np.array(percentLesion_expert1) - np.array(percentLesion_predict))))\n",
    "\n",
    "\n",
    "print()    \n",
    "print(\"Raw Error:\", bias_raw, \"+/-\", StD_raw)\n",
    "print(\"Mean absolute error:\", Mean_Abs_error)\n",
    "print(\"StD absolute error:\", StD_Abs_error)\n",
    "\n",
    "bias_relative = np.mean(((np.array(percentLesion_expert1) - np.array(percentLesion_predict))/np.array(percentLesion_expert1)))\n",
    "StD_relative = np.std(np.abs((np.array(percentLesion_expert1) - np.array(percentLesion_predict))/np.array(percentLesion_expert1)))\n",
    "    \n",
    "print()    \n",
    "print(\"Relative Error:\", bias_relative, \"+/-\", StD_relative)\n",
    " \n",
    "print(\"Mean Lesion Coverage for Expert 1:\", np.mean(percentLesion_expert1))\n",
    "print(\"Mean Lesion Coverage for Model:\", np.mean(percentLesion_predict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs((np.array(percentLesion_expert1) - np.array(percentLesion_predict))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('../data/kevin_data/qmetric/t2maps/9120358_4.npy')\n",
    "plt.imshow(a[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/kevin_data/qmetric/t2_projected/9909311_4.npy.pickle', 'rb') as handle:\n",
    "    dict_a = pickle.load(handle)\n",
    "\n",
    "with open('../data/kevin_data/qmetric/t2_projected/9909311_8.npy.pickle', 'rb') as handle:\n",
    "    dict_b = pickle.load(handle)\n",
    "    \n",
    "a = make_projection_proportional(dict_a)\n",
    "b = make_projection_proportional(dict_b)\n",
    "a,b = align_projections(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pix = np.sum(b!=0)\n",
    "where_b = np.where(b)\n",
    "where_a = np.where(a)\n",
    "\n",
    "dmap = np.zeros_like(b)\n",
    "for i in range(num_pix):\n",
    "    t2_b = b[where_b[0][i], where_b[1][i]]\n",
    "    \n",
    "    distances_r = where_a[0] - where_b[0][i]\n",
    "    distances_c = where_a[1] - where_b[1][i]\n",
    "    distances = np.sqrt(distances_r**2 + distances_c**2)\n",
    "    index = np.argmin(distances)\n",
    "    t2_a = a[where_a[0][index], where_a[1][index]]\n",
    "    \n",
    "    change = t2_b - t2_a\n",
    "    dmap[where_b[0][i], where_b[1][i]] = change\n",
    "plt.imshow(dmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difference_map_utils import eroded_and_mask\n",
    "mask = eroded_and_mask(dmap!=0,dmap!=0)\n",
    "dmap = dmap*mask\n",
    "plt.imshow(dmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.array([10,2,1,5])\n",
    "i = np.argsort(a)\n",
    "a[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([[10,1,5,3],[8,9,7,2],[1,2,3,4],[7,6,5,4]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[[0,0,1],[2,3,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
