{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import sys\n",
    "sys.path.insert(0, 'lib')\n",
    "import numpy as np\n",
    "import random\n",
    "import pydicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "import pydicom\n",
    "from shutil import copyfile\n",
    "import nibabel as nib\n",
    "import scipy.ndimage as ndimage\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "from utils import make_giant_mat, make_dictionary, make_echo_dict\n",
    "from difference_map_utils import make_difference\n",
    "from cluster_utils import threshold_diffmaps, strip_empty_lines, resize\n",
    "from lesion_utils import *\n",
    "from inference_utils import run_inference\n",
    "from make_inference_csv import *\n",
    "from compare_segmentations import get_dice_scores, get_jaccard_indices, compare_segmentation_masks, compare_region_means, compare_region_changes\n",
    "from loss_functions import coefficient_of_variation\n",
    "from figure_utils import plot_mean_val_comparisons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify which subjects you want to analyze using their OAI Patient ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9013634' '9120358' '9123289' '9245760' '9260036' '9279874' '9376146'\n",
      " '9405107' '9435250' '9458093' '9518827' '9529761' '9543086' '9909311']\n",
      "\n",
      "['9013634' '9120358' '9123289' '9245760' '9260036' '9279874' '9376146'\n",
      " '9405107' '9435250' '9458093' '9518827' '9529761' '9543086' '9909311']\n",
      "[4 8 8 4 8 4 8 8 4 8 8 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "with open('/data/dominik_data/train_val_test/pid_train.pickle', 'rb') as f:    \n",
    "    pid_train = pickle.load(f)\n",
    "    \n",
    "with open('/data/dominik_data/train_val_test/pid_val.pickle', 'rb') as f:    \n",
    "    pid_val = pickle.load(f)\n",
    "    \n",
    "with open('/data/dominik_data/train_val_test/pid_test.pickle', 'rb') as f:    \n",
    "    pid_test = pickle.load(f)\n",
    "\n",
    "# with open('/data/dominik_data/train_val_test/pid_test_expert2.pickle', 'rb') as f:\n",
    "#     pid_expert2 = pickle.load(f)\n",
    "    \n",
    "# with open('/data/dominik_data/train_val_test/pid_test_expert2_years.pickle', 'rb') as f:\n",
    "#     pid_expert2_yrs = pickle.load(f)\n",
    "\n",
    "with open('/data/dominik_data/train_val_test/pid_test_expert2_round2.pickle', 'rb') as f:\n",
    "    pid_expert2 = pickle.load(f)\n",
    "    \n",
    "with open('/data/dominik_data/train_val_test/pid_test_expert2_years_round2.pickle', 'rb') as f:\n",
    "    pid_expert2_yrs = pickle.load(f)\n",
    "\n",
    "print(np.sort(pid_test))\n",
    "print()\n",
    "print(np.sort(pid_expert2))\n",
    "print(pid_expert2_yrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Pandas Data Frame and CSV file to specify which image files you want to have analyzed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_pd = make_expert_csv_all_years(pID=pid_test,img_dir='/data/kevin_data/images', dir_to_save='/data/kevin_data/predicted')\n",
    "\n",
    "expert1_pd = make_expert_csv_all_years(pID=pid_test, img_dir='/data/kevin_data/images',dir_to_save='/data/kevin_data/qmetric')\n",
    "\n",
    "# We only have segmentations for one timepoint for the subjects segmented by expert2 and these are nifti files\n",
    "expert2_pd = make_expert_csv_specific_years(pID=pid_expert2, \n",
    "                                            years=pid_expert2_yrs, \n",
    "                                            img_dir='/data/kevin_data/images', \n",
    "                                            dir_to_save='/data/kevin_data/expert2', \n",
    "                                            seg_provided=True, \n",
    "                                            seg_format = \"numpy\")\n",
    "\n",
    "predict_subset_pd = make_expert_csv_specific_years(pID=pid_expert2, \n",
    "                                            years=pid_expert2_yrs, \n",
    "                                            img_dir='/data/kevin_data/images', \n",
    "                                            dir_to_save='/data/kevin_data/predicted', \n",
    "                                            seg_provided=True, \n",
    "                                            seg_format = \"numpy\",\n",
    "                                            csv_filename = 'file_paths_subset.csv')\n",
    "\n",
    "expert1_subset_pd = make_expert_csv_specific_years(pID=pid_expert2, \n",
    "                                            years=pid_expert2_yrs, \n",
    "                                            img_dir='/data/kevin_data/images', \n",
    "                                            dir_to_save='/data/kevin_data/qmetric', \n",
    "                                            seg_provided=True, \n",
    "                                            seg_format = \"numpy\",\n",
    "                                            csv_filename = 'file_paths_subset.csv')\n",
    "# for f in np.array(expert2_pd.image_dir):\n",
    "#     print(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Segmentations and T2 maps for your MESE images\n",
    "- If you provide a value for the 'expert_pd' argument, it will use your provided segmentations\n",
    "\n",
    "- If you provide a value for the 'to_segment_pd' argument, it will automatically segment the cartilage and then use that auto-segmentation to generate the T2 maps. By default, this uses our trained model, but model weights can be changed via the 'model_weights_file' argument and the model can be changed by altering the inference.get_model function in inference.py. \n",
    "\n",
    "- In addition to generating 3D T2 maps, it also provides the segmentations used to generate those T2 maps as 3D numpy arrays and json files that summarize the avg T2 value in each anatomical region of the cartilage plate\n",
    "\n",
    "- These results are all saved in the destinations specied in your Pandas dataframe (expert_pd or to_segment_pd) that you made in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------\n",
      "Automatically segmenting images and using those segmentations to analyze MESE MRIs\n",
      "-----------------------------------------------------------------------------------\n",
      "\n",
      "/data/kevin_data/images/YR4/9543086/T2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b31fcaa7233d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_segment_pd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_pd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_weight_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./model_weights/model_weights_quartileNormalization_echoAug.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# run_inference(expert_pd = predict_pd)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# run_inference(expert_pd = expert1_pd)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AutomaticKneeMRISegmentation/inference_utils.py\u001b[0m in \u001b[0;36mrun_inference\u001b[0;34m(expert_pd, to_segment_pd, model_weight_file)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-----------------------------------------------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mmodel_segmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_segment_pd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_weight_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_weight_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AutomaticKneeMRISegmentation/inference_utils.py\u001b[0m in \u001b[0;36mmodel_segmentation\u001b[0;34m(file_array, model_weight_file, normalization)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# Get model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weight_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;31m# Estimate segmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AutomaticKneeMRISegmentation/inference_utils.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(model_weight_file)\u001b[0m\n\u001b[1;32m     23\u001b[0m     '''\n\u001b[1;32m     24\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet_2d_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weight_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[0;32m-> 1230\u001b[0;31m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[1;32m   1231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \"\"\"\n\u001b[1;32m   1182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'keras_version'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m         \u001b[0moriginal_keras_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keras_version'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0moriginal_keras_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "run_inference(to_segment_pd = predict_pd, model_weight_file = './model_weights/model_weights_quartileNormalization_echoAug.h5')\n",
    "# run_inference(expert_pd = predict_pd)\n",
    "\n",
    "# run_inference(expert_pd = expert1_pd)\n",
    "              \n",
    "# run_inference(expert_pd = expert2_pd)\n",
    "\n",
    "# We don't need to generate additional segmentations for the 'predict_subset_pd' or 'expert1_subset_pd' \n",
    "# because they are already generated as part of the 'predict_pd' and 'expert1_pd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip the expert segmentations if you haven't already\n",
    "# for file in os.listdir('/data/kevin_data/expert2/segmentations'):\n",
    "#     if file[-4:]=='.npy':\n",
    "#         temp = np.load(os.path.join('/data/kevin_data/expert2/segmentations',file))\n",
    "#         temp = np.flip(temp, axis = 0)\n",
    "#         np.save(os.path.join('/data/kevin_data/expert2/segmentations',file),temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use cluster analysis to identify cartilage lesions developing over time\n",
    "<img src=\"ClusterAnalysisExample.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "Find the percentage of the femoral cartilage surface area that is affected by cartilage lesions. In this context, a lesion is a localized area of cartilage that has increased in T2 value over time more than the surrounding area. You can adjust the settings in calculate_group_lesion_area() to make the criteria for lesions more or less strict based on how large a cluster must be and how much the T2 value must increase. \n",
    "\n",
    "Lesions are identified using methods adapted from the following manuscript:\n",
    "\n",
    "Monu, Uchechukwuka D., et al. \"Cluster analysis of quantitative MRI T2 and T1ρ relaxation times of cartilage identifies differences between healthy and ACL-injured individuals at 3T.\" Osteoarthritis and cartilage 25.4 (2017): 513-520.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paths = np.array(predict_pd.t2_projected_path)\n",
    "paths = [i + '.pickle' for i in paths]\n",
    "source1_time1 = np.sort([i for i in paths if i[-12]=='4'])\n",
    "source1_time2 = np.sort([i for i in paths if i[-12]=='8'])\n",
    "\n",
    "paths = np.array(expert1_pd.t2_projected_path)\n",
    "paths = [i + '.pickle' for i in paths]\n",
    "source2_time1 = np.sort([i for i in paths if i[-12]=='4'])\n",
    "source2_time2 = np.sort([i for i in paths if i[-12]=='8'])\n",
    "\n",
    "percentLesion_expert1 = calculate_group_lesion_area(timepoint1=source2_time1,\n",
    "                                                     timepoint2=source2_time2, \n",
    "#                                                      value_threshold = 9,\n",
    "                                                     sigma_multiple = 1,\n",
    "#                                                      area_value_threshold = 12.4,\n",
    "                                                     area_fraction_threshold = .01, \n",
    "                                                     area_percentile_threshold = None,\n",
    "                                                     display=False,\n",
    "                                                     save_path_list=None)\n",
    "\n",
    "print()\n",
    "print(\"--\"*10)\n",
    "\n",
    "\n",
    "percentLesion_predict = calculate_group_lesion_area(timepoint1=source1_time1,\n",
    "                                                     timepoint2=source1_time2, \n",
    "#                                                      value_threshold = 9,\n",
    "                                                     sigma_multiple = 1,\n",
    "#                                                      area_value_threshold = 12.4,\n",
    "                                                     area_fraction_threshold = .01, \n",
    "                                                     area_percentile_threshold = None,\n",
    "                                                     display=False,\n",
    "                                                     save_path_list = None)\n",
    "\n",
    "    \n",
    "\n",
    "# SAVE THE RESIZED PROJECTIONS AND LESION MAPS!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare two segmentation approaches (e.g. manual vs automated)\n",
    "- Quantify how closely the two segmentations agree with one another using Dice Score and Jaccard Index\n",
    "- Quantify how closely the downstream T2 measurements correlate for each region using Pearson correlation\n",
    "- Quantify the mean absolute difference in T2 measurements for each region\n",
    "- Quantify the agreement in the percentage of the cartilage plate that has lesion via Pearson correlation\n",
    "- Quantify the agreement in the lesions identified using Dice Score and Jaccard Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify how closely the two segmentations agree with one another using Dice Score and Jaccard Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Qmetric vs Model: Full test set\")\n",
    "dice_expert1_model, jaccard_expert1_model = compare_segmentation_masks(expert1_pd, \n",
    "                                                                       predict_pd, \n",
    "                                                                       display = True)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print()\n",
    "print(\"Qmetric vs Model: Test subset\")\n",
    "dice_expert1_model_subset, jaccard_expert1_model_subset = compare_segmentation_masks(expert1_subset_pd, \n",
    "                                                                                     predict_subset_pd, \n",
    "                                                                                     display = True)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print(\"Qmetric vs Expert 2: Test subset\")\n",
    "\n",
    "dice_expert1_expert2, jaccard_expert1_expert2 = compare_segmentation_masks(expert1_subset_pd, \n",
    "                                                                           expert2_pd, \n",
    "                                                                           display = True)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print(\"Model vs Expert 2: Test subset\")\n",
    "\n",
    "dice_expert1_expert2, jaccard_expert1_expert2 = compare_segmentation_masks(predict_subset_pd, \n",
    "                                                                           expert2_pd, \n",
    "                                                                           display = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how well they agree in terms of the average T2 value in each cartilage region of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlation_dict_e1_m, abs_diff_dict_e1_m, cv_e1_m, t_e1_m, cohen_e1_m = compare_region_means(list(expert1_pd.t2_region_json_path), \n",
    "                                                                            list(predict_pd.t2_region_json_path), \n",
    "                                                                            results_path=None,\n",
    "                                                                            correlation_method = 'spearman',\n",
    "                                                                            bland_altman = False)\n",
    "\n",
    "correlation_dict_e1_m_subset, abs_diff_dict_e1_m_subset, cv_e1_m_subset, t_e1_m_subset, cohen_e1_m_subset = compare_region_means(list(expert1_subset_pd.t2_region_json_path), \n",
    "                                                                                                list(predict_subset_pd.t2_region_json_path), \n",
    "                                                                                                results_path=None,\n",
    "                                                                                                correlation_method = 'spearman')\n",
    "\n",
    "correlation_dict_e1_e2, abs_diff_dict_e1_e2, cv_e1_e2, t_e1_e2, cohen_e1_e2 = compare_region_means(list(expert1_subset_pd.t2_region_json_path), \n",
    "                                                                            list(expert2_pd.t2_region_json_path), \n",
    "                                                                            results_path=None,\n",
    "                                                                            correlation_method = 'spearman')\n",
    "\n",
    "correlation_dict_e2_m, abs_diff_dict_e2_m, cv_e2_m, t_e2_m, _cohen_e1_e2 = compare_region_means(list(expert2_pd.t2_region_json_path), \n",
    "                                                                            list(predict_subset_pd.t2_region_json_path), \n",
    "                                                                            results_path=None,\n",
    "                                                                            correlation_method = 'spearman')\n",
    "\n",
    "plot_mean_val_comparisons(abs_diff_dict_e1_e2, \n",
    "                          abs_diff_dict_e1_m_subset, \n",
    "                          'Reader 2', \n",
    "                          'Model',\n",
    "                          error_bar='ci')\n",
    "\n",
    "# plot_mean_val_comparisons(abs_diff_dict_e1_e2, \n",
    "#                           abs_diff_dict_e1_m_subset, \n",
    "#                           'Reader 2', \n",
    "#                           'Model',\n",
    "#                           error_bar='ci')\n",
    "\n",
    "# plot_mean_val_comparisons(abs_diff_dict_e1_e2, \n",
    "#                           abs_diff_dict_e2_m, \n",
    "#                           'Reader 1', \n",
    "#                           'Model',\n",
    "#                           error_bar = 'ci')\n",
    "\n",
    "\n",
    "roi_list = np.array(['SLA', 'SLC', 'SLP', 'SMA', 'SMC', 'SMP', 'DLA', 'DLC', 'DLP', 'DMA', 'DMC', 'DMP'])\n",
    "print(\"CORRELATION: EXPERT1 vs Model (SUBSET)\")\n",
    "roi_corr_mean = 0\n",
    "for k,v in correlation_dict_e1_m_subset.items():\n",
    "    print(k, v)\n",
    "    if k in roi_list:\n",
    "        roi_corr_mean += v[0]\n",
    "roi_corr_mean = roi_corr_mean / len(roi_list)\n",
    "print()\n",
    "print(\"ROI CORR MEAN:\", roi_corr_mean)\n",
    "print()    \n",
    "print()\n",
    "\n",
    "print(\"Mean Abs Error: EXPERT1 vs Model (SUBSET\")\n",
    "roi_mae_mean = 0\n",
    "for k,v in abs_diff_dict_e1_m_subset.items():\n",
    "    print(k, v)\n",
    "    if k in roi_list:\n",
    "        roi_mae_mean += v[0]\n",
    "roi_mae_mean = roi_mae_mean / len(roi_list)\n",
    "print()\n",
    "print(\"ROI MAE MEAN:\", roi_mae_mean)\n",
    "print()    \n",
    "print()   \n",
    "print()\n",
    "print(\"Coefficient of Variation: EXPERT1 vs EXPERT2\")\n",
    "for k,v in cv_e1_e2.items():\n",
    "    print(k, v)\n",
    "    \n",
    "    \n",
    "    \n",
    "print()\n",
    "print(\"Cohen's D: EXPERT1 vs EXPERT2\")\n",
    "for k,v in cohen_e1_e2.items():\n",
    "    print(k, v)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how well they agree in terms of the average T2 change over time in each cartilage region of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expert1_regions = list(expert1_pd.t2_region_json_path)\n",
    "model_regions = list(predict_pd.t2_region_json_path)\n",
    "\n",
    "\n",
    "source1_regions1 = [i for i in expert1_regions if i[-6]=='4']# and '9120358' not in i]\n",
    "source1_regions2 = [i for i in expert1_regions if i[-6]=='8']#and '9120358' not in i]\n",
    "source2_regions1 = [i for i in model_regions if i[-6]=='4']#and '9120358' not in i]\n",
    "source2_regions2 = [i for i in model_regions if i[-6]=='8']#and '9120358' not in i]\n",
    "\n",
    "if len(source1_regions1)==len(source1_regions2):\n",
    "    catch = compare_region_changes(source1_regions1,\n",
    "                                   source1_regions2,\n",
    "                                   source2_regions1,\n",
    "                                   source2_regions2, \n",
    "                                   results_path=None,\n",
    "                                   correlation_method = 'spearman',\n",
    "                                   bland_altman = True)  \n",
    "    \n",
    "    (change_correlation_dict, change_mean_abs_diff_dict, change_cv_dict, change_ttest_dict, change_dict, change_cohen) = catch\n",
    "    \n",
    "print(\"CORRELATION EXPERT 1 VS MODEL\")\n",
    "for k,v in change_correlation_dict.items():\n",
    "    print(k, v)\n",
    "    \n",
    "\n",
    "print()\n",
    "print(\"MEAN ABS DIFFERENCE EXPERT 1 VS MODEL\")\n",
    "for k,v in change_mean_abs_diff_dict.items():\n",
    "    print(k, v)\n",
    "print()\n",
    "\n",
    "    \n",
    "print()\n",
    "print(\"MEAN CHANGE ACCORDING TO EXPERT 1\")\n",
    "for k,v in change_dict[1].items():\n",
    "    print(k, np.mean(v))\n",
    "    \n",
    "    \n",
    "print()\n",
    "print(\"COHEN's D ACCORDING TO EXPERT 1\")\n",
    "for k,v in change_cohen.items():\n",
    "    print(k, np.mean(v))\n",
    "\n",
    "\n",
    "for k in change_dict[1].keys():\n",
    "    plt.scatter(change_dict[1][k],change_dict[2][k]) \n",
    "    plt.title(k)\n",
    "    plt.plot([0,0],[-5,5],'orange')\n",
    "    plt.plot([-5,5],[0,0], 'orange')\n",
    "    plt.plot([-1.73,-1.73],[0,-4])\n",
    "    plt.plot([1.73, 1.73],[0,-4])\n",
    "    plt.plot([-.61,-.61],[0,-4])\n",
    "    plt.plot([.61, .61],[0,-4])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how well they agree in terms of the cartilage lesions that are identified as developing over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(percentLesion_expert1, percentLesion_predict)\n",
    "plt.title(\"Correlation:\" + str(spearmanr(percentLesion_expert1, percentLesion_predict)))\n",
    "plt.xlabel(\"Source 1: Fraction of cartilage affected\")\n",
    "plt.ylabel(\"Source 2: Fraction of cartilage affected\")\n",
    "plt.plot([.03,.15],[.03,.15])\n",
    "plt.plot(np.unique(percentLesion_expert1), np.poly1d(np.polyfit(percentLesion_expert1, percentLesion_predict, 1))(np.unique(percentLesion_expert1)))\n",
    "plt.legend(['unity','best fit','data points'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "bias_raw = np.mean(((np.array(percentLesion_expert1) - np.array(percentLesion_predict))))\n",
    "StD_raw = np.std(np.abs((np.array(percentLesion_expert1) - np.array(percentLesion_predict))))\n",
    "Mean_Abs_error = np.mean(np.abs((np.array(percentLesion_expert1) - np.array(percentLesion_predict))))\n",
    "StD_Abs_error = np.std(np.abs((np.array(percentLesion_expert1) - np.array(percentLesion_predict))))\n",
    "\n",
    "\n",
    "print()    \n",
    "print(\"Raw Error:\", bias_raw, \"+/-\", StD_raw)\n",
    "print(\"Mean absolute error:\", Mean_Abs_error)\n",
    "print(\"StD absolute error:\", StD_Abs_error)\n",
    "\n",
    "bias_relative = np.mean(((np.array(percentLesion_expert1) - np.array(percentLesion_predict))/np.array(percentLesion_expert1)))\n",
    "StD_relative = np.std(np.abs((np.array(percentLesion_expert1) - np.array(percentLesion_predict))/np.array(percentLesion_expert1)))\n",
    "    \n",
    "print()    \n",
    "print(\"Relative Error:\", bias_relative, \"+/-\", StD_relative)\n",
    " \n",
    "print(\"Mean Lesion Coverage for Expert 1:\", np.mean(percentLesion_expert1))\n",
    "print(\"Mean Lesion Coverage for Model:\", np.mean(percentLesion_predict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs((np.array(percentLesion_expert1) - np.array(percentLesion_predict))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('/data/kevin_data/qmetric/t2maps/9120358_4.npy')\n",
    "plt.imshow(a[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/kevin_data/qmetric/t2_projected/9909311_4.npy.pickle', 'rb') as handle:\n",
    "    dict_a = pickle.load(handle)\n",
    "\n",
    "with open('/data/kevin_data/qmetric/t2_projected/9909311_8.npy.pickle', 'rb') as handle:\n",
    "    dict_b = pickle.load(handle)\n",
    "    \n",
    "a = make_projection_proportional(dict_a)\n",
    "b = make_projection_proportional(dict_b)\n",
    "a,b = align_projections(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pix = np.sum(b!=0)\n",
    "where_b = np.where(b)\n",
    "where_a = np.where(a)\n",
    "\n",
    "dmap = np.zeros_like(b)\n",
    "for i in range(num_pix):\n",
    "    t2_b = b[where_b[0][i], where_b[1][i]]\n",
    "    \n",
    "    distances_r = where_a[0] - where_b[0][i]\n",
    "    distances_c = where_a[1] - where_b[1][i]\n",
    "    distances = np.sqrt(distances_r**2 + distances_c**2)\n",
    "    index = np.argmin(distances)\n",
    "    t2_a = a[where_a[0][index], where_a[1][index]]\n",
    "    \n",
    "    change = t2_b - t2_a\n",
    "    dmap[where_b[0][i], where_b[1][i]] = change\n",
    "plt.imshow(dmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difference_map_utils import eroded_and_mask\n",
    "mask = eroded_and_mask(dmap!=0,dmap!=0)\n",
    "dmap = dmap*mask\n",
    "plt.imshow(dmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.array([10,2,1,5])\n",
    "i = np.argsort(a)\n",
    "a[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([[10,1,5,3],[8,9,7,2],[1,2,3,4],[7,6,5,4]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[[0,0,1],[2,3,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
